{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9302ffd9",
   "metadata": {},
   "source": [
    "# Eigen Portfolios\n",
    "#### Authors: António Salomão, Carolina Domingues, Tim Gajewski\n",
    "##### Credits: PMC© Quant Team, Fall 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446798d1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519c3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# YFinance\n",
    "import yfinance as yf\n",
    "\n",
    "# Pytickersymbols\n",
    "import pytickersymbols\n",
    "from pytickersymbols import PyTickerSymbols\n",
    "\n",
    "# Common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Numpy\n",
    "from numpy.linalg import eig\n",
    "\n",
    "# PLotly\n",
    "import plotly.express as px\n",
    "\n",
    "# Pandas Datareader for Fama French Regresseion\n",
    "import pandas_datareader.data as reader\n",
    "\n",
    "#\n",
    "import statsmodels.api as sn\n",
    "\n",
    "#\n",
    "import datetime\n",
    "\n",
    "#\n",
    "import quantstats as qs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036849a8",
   "metadata": {},
   "source": [
    "\n",
    "### Data cleansing (Adjusted Close)\n",
    "\n",
    "We'll drop columns that have \"too many\" NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98384249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_by_nan(df, thresh, fill_na):\n",
    "    # Assert\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    # Avoid overwritting original dataframe\n",
    "    df = df.copy()\n",
    "    # Compute the fraction of missing values per column\n",
    "    data_fractions = 1. - df.isnull().mean().sort_values(ascending=False)\n",
    "    drop_list = sorted(list(data_fractions[data_fractions < thresh].index))\n",
    "    # Drop problematic columns\n",
    "    if drop_list:\n",
    "        df = df.drop(drop_list, axis=1)\n",
    "    # Fill missing values with the last value avail. (forward-fill)\n",
    "    if fill_na:\n",
    "        df = df.fillna(method=\"ffill\")\n",
    "        df = df.dropna(axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b7dcf",
   "metadata": {},
   "source": [
    "### Eigenportfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1ff09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigenportfolio (startdate, enddate, ticker):    \n",
    "    # Get US ticker symbols (SP500)\n",
    "    stock_data = PyTickerSymbols()\n",
    "    us_stocks = list(stock_data.get_stocks_by_index(ticker))\n",
    "    us_ticker_symbols = [k[\"symbol\"] for k in us_stocks]\n",
    "\n",
    "    # YFinance\n",
    "    us_hist_df = yf.download(tickers=us_ticker_symbols,\n",
    "                             start=startdate,\n",
    "                             end=enddate,\n",
    "                             interval=\"1d\")\n",
    "\n",
    "    us_hist_df.index = pd.to_datetime(us_hist_df.index)\n",
    "\n",
    "\n",
    "    # Removing NaN values and cleaning columns\n",
    "    us_adjClose = clean_df_by_nan(df=us_hist_df[\"Adj Close\"], thresh=0.90, fill_na=True)\n",
    "\n",
    "\n",
    "    # Individual securities\n",
    "    us_log_rets = np.log(us_adjClose) - np.log(us_adjClose.shift(1))\n",
    "    us_log_rets = us_log_rets.dropna(axis=0)\n",
    "\n",
    "\n",
    "    us_cov_log_rets = us_log_rets.cov()\n",
    "    cov_fig = px.imshow(us_cov_log_rets, width=500)\n",
    "    us_cov_log_rets.shape\n",
    "\n",
    "\n",
    "    # Standardizing\n",
    "    mu, sigma = us_log_rets.mean(), us_log_rets.std()\n",
    "    us_log_rets_rescaled = (us_log_rets.sub(mu, axis=1)).div(sigma, axis=1)\n",
    "\n",
    "\n",
    "    # Train-test split\n",
    "    cutoff = 0.8\n",
    "    n = len(us_log_rets_rescaled)\n",
    "    X_train_raw, X_test_raw = us_log_rets[:int(n*cutoff)], us_log_rets[int(n*cutoff):]\n",
    "    X_train_rescaled , X_test_rescaled = us_log_rets_rescaled[:int(n*cutoff)], us_log_rets_rescaled[int(n*cutoff):]\n",
    "\n",
    "\n",
    "    X_train_cov = X_train_rescaled.cov()\n",
    "    eigenvalues, eigenvectors = eig(X_train_cov)\n",
    "\n",
    "\n",
    "    exp_var_ratios = eigenvalues / eigenvalues.sum()\n",
    "\n",
    "\n",
    "    # Explained variace ratio by Top Factors\n",
    "    exp_var_ratios_fig = px.bar(x=exp_var_ratios[:20],\n",
    "                                labels={\"x\": \"Explained Variance\", \"y\": \"Component\"},\n",
    "                                height=400,\n",
    "                                width=800)\n",
    "\n",
    "    # Explained cumulative variance\n",
    "    exp_var_cumul = np.cumsum(exp_var_ratios)\n",
    "    exp_var_cumul_fig = px.area(x=range(1, exp_var_cumul.shape[0] + 1),\n",
    "                                y=exp_var_cumul,\n",
    "                                labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"},\n",
    "                                height=400,\n",
    "                                width=800)\n",
    "\n",
    "\n",
    "    eigenPortfolios = list(map(lambda x: x / sum(x) , eigenvectors))\n",
    "    eigenPortfolios_df = pd.DataFrame(eigenPortfolios, columns=X_train_raw.columns)\n",
    "\n",
    "    for i in range(5):\n",
    "\n",
    "        fig_i = px.bar(eigenPortfolios_df.iloc[i].to_frame(),\n",
    "                       title=f\"Eigen Portfolio #{i} | Eigenvalue: {eigenvalues[i]:.2f} | Explained Variance: {exp_var_ratios[i]:.2f}\",\n",
    "                       labels={\"index\":\"Ticker\", \"value\": \"Weight\"},\n",
    "                       width=1000,\n",
    "                       height=500)\n",
    "\n",
    "\n",
    "    def get_sharpe_ratio(x):\n",
    "        assert len(x.shape) == 1\n",
    "        x = x.copy()\n",
    "        ann_ret = x.mean() * 252.\n",
    "        ann_std = x.std() * np.sqrt(252.)\n",
    "        sr = ann_ret / ann_std\n",
    "        return ann_ret, ann_std, sr\n",
    "\n",
    "    my_eigenports = {\"Eigen Portfolio #\": [],\n",
    "                               \"Weights\": [],\n",
    "                                \"Return\": [],\n",
    "                            \"Volatility\": [],\n",
    "                          \"Sharpe Ratio\": []}\n",
    "\n",
    "    # Compute Sharpe Ratio for every eigen portfolio\n",
    "    for i in range(len(eigenPortfolios_df)):\n",
    "        eigenPort_i = eigenPortfolios_df.iloc[i].to_numpy()\n",
    "        rets_i = np.dot(X_train_raw, eigenPort_i)\n",
    "        ret, vol, sr = get_sharpe_ratio(rets_i)\n",
    "        my_eigenports[\"Eigen Portfolio #\"].append(str(i))          \n",
    "        my_eigenports[\"Weights\"].append(eigenPort_i)\n",
    "        my_eigenports[\"Return\"].append(ret)\n",
    "        my_eigenports[\"Volatility\"].append(vol)\n",
    "        my_eigenports[\"Sharpe Ratio\"].append(sr)\n",
    "\n",
    "\n",
    "    eigenports_sr_df = pd.DataFrame(my_eigenports[\"Sharpe Ratio\"], columns=[\"Sharpe Ratio\"])\n",
    "    eigenports_sr_sorted_df = eigenports_sr_df.sort_values(by=\"Sharpe Ratio\", ascending=False)\n",
    "\n",
    "    eigenports_sr_fig1 = px.bar(x=list(map(str, eigenports_sr_df.index.to_numpy().squeeze())),\n",
    "                                y=eigenports_sr_df.to_numpy().squeeze(),\n",
    "                                labels = {\"x\": \"Eigenportfolio #\", \"y\": \"Sharpe Ratio\"},\n",
    "                                title=\"Eigen Porfolios sorted by Eigenvalues (explained variance)\",\n",
    "                                width=1000,\n",
    "                                height=500)\n",
    "\n",
    "    eigenports_sr_fig2 = px.bar(x=list(map(str, eigenports_sr_sorted_df.index.to_numpy().squeeze())),\n",
    "                                y=eigenports_sr_sorted_df.to_numpy().squeeze(),\n",
    "                                labels={\"x\": \"Eigenportfolio #\", \"y\": \"Sharpe Ratio\"},\n",
    "                                title=\"Eigen Porfolios sorted by Sharpe Ratio\",\n",
    "                                width=1000,\n",
    "                                height=500)\n",
    "\n",
    "\n",
    "    def get_eigen_rets(test_df, n_eigen_portfolios):\n",
    "\n",
    "        # Copy\n",
    "        test = test_df.copy()\n",
    "        eigenports_sr = eigenports_sr_df.copy()\n",
    "        eigenports_dict = my_eigenports.copy()\n",
    "\n",
    "        # Sort by sharpe ratio\n",
    "        eigenports_sr = eigenports_sr.sort_values(by=\"Sharpe Ratio\", ascending=False)\n",
    "\n",
    "        # Eigen portfolios\n",
    "        eigen_ports = eigenports_sr.index[:n_eigen_portfolios]\n",
    "        eigen_weights = [eigenports_dict[\"Weights\"][i] for i in eigen_ports]\n",
    "\n",
    "        # Returns\n",
    "        eigen_rets = np.array(list(map(lambda n: np.dot(test, n), eigen_weights)))\n",
    "        eigen_df = pd.DataFrame(eigen_rets.T, \n",
    "                                columns=list(map(str, eigen_ports)), \n",
    "                                index=test.index)\n",
    "\n",
    "        # Equal-weighted eigen portfolio\n",
    "        ew_eigen_rets = (eigen_rets.T * (1./eigen_rets.T.shape[1])).sum(axis=1)\n",
    "        ew_eigen_df = pd.DataFrame(ew_eigen_rets,\n",
    "                                   columns=[\"EW-Eigen\"],\n",
    "                                   index=test.index)\n",
    "        # Equal-weighted SP500\n",
    "        ew_sp_rets = (test * (1./test.shape[1])).sum(axis=1)\n",
    "        ew_sp_df = pd.DataFrame(ew_sp_rets,\n",
    "                                columns=[\"EW-SP500\"],\n",
    "                                index=test.index)\n",
    "\n",
    "        all_eigen_df = eigen_df.join([ew_eigen_df, ew_sp_df])\n",
    "\n",
    "        return all_eigen_df\n",
    "\n",
    "    def get_eigen_stats(rets_df):\n",
    "\n",
    "        rets_df = rets_df.copy()\n",
    "\n",
    "        # Compute sharpe ratio\n",
    "        sr = np.array(rets_df.apply(get_sharpe_ratio, axis=0).T)\n",
    "\n",
    "        stats = pd.DataFrame(data=sr,\n",
    "                             columns=[\"Return\", \"Volatility\", \"SR\"],\n",
    "                             index=rets_df.columns).sort_values(by=\"SR\", ascending=False)\n",
    "        return stats\n",
    "\n",
    "\n",
    "    ew_eigen_rets_train = list(map(lambda eig_n: get_eigen_rets(X_train_raw, eig_n), range(1, 80)))\n",
    "    ew_eigen_stats_train = list(map(lambda eig: get_eigen_stats(eig).loc[\"EW-Eigen\"].values, ew_eigen_rets_train))\n",
    "    ew_eigen_stats_train_df = pd.DataFrame(ew_eigen_stats_train, columns=[\"Return\", \"Volatility\", \"SR\"])\n",
    "\n",
    "    ew_eigen_rets_test = list(map(lambda eig_n: get_eigen_rets(X_test_raw, eig_n), range(1, 80)))\n",
    "    ew_eigen_stats_test = list(map(lambda eig: get_eigen_stats(eig).loc[\"EW-Eigen\"].values, ew_eigen_rets_test))\n",
    "    ew_eigen_stats_test_df = pd.DataFrame(ew_eigen_stats_test, columns=[\"Return\", \"Volatility\", \"SR\"])\n",
    "\n",
    "\n",
    "    ew_ret_comparison = pd.DataFrame(data=[ew_eigen_stats_train_df[\"Return\"], ew_eigen_stats_test_df[\"Return\"]],\n",
    "                                     index=[\"Train\", \"Test\"]).T\n",
    "\n",
    "    ew_vol_comparison = pd.DataFrame(data=[ew_eigen_stats_train_df[\"Volatility\"], ew_eigen_stats_test_df[\"Volatility\"]],\n",
    "                                     index=[\"Train\", \"Test\"]).T\n",
    "\n",
    "    ew_sr_comparison = pd.DataFrame(data=[ew_eigen_stats_train_df[\"SR\"], ew_eigen_stats_test_df[\"SR\"]],\n",
    "                                    index=[\"Train\", \"Test\"]).T\n",
    "\n",
    "    ret_fig = px.line(ew_ret_comparison, \n",
    "                      title=\"Return\", \n",
    "                      labels={\"index\" : \"EW-Eigen #\"})\n",
    "\n",
    "    vol_fig = px.line(ew_vol_comparison, \n",
    "                      title=\"Volatility\", \n",
    "                      labels={\"index\" : \"EW-Eigen #\"})\n",
    "\n",
    "    sr_fig = px.line(ew_sr_comparison, \n",
    "                     title=\"Sharpe Ratio\", \n",
    "                     labels={\"index\" : \"EW-Eigen #\"})\n",
    "\n",
    "    ew_ret_comparison.sort_values(by=\"Train\", ascending=False).head(5)\n",
    "    ew_vol_comparison.sort_values(by=\"Train\", ascending=True).head(5)\n",
    "    ew_sr_comparison.sort_values(by=\"Train\", ascending=False).head(5)\n",
    "\n",
    "\n",
    "    eigen_train_rets = get_eigen_rets(test_df=X_train_raw, n_eigen_portfolios=14)\n",
    "\n",
    "    # Sharpe Ratios\n",
    "    eigen_train_sr = get_eigen_stats(eigen_train_rets)\n",
    "    eigen_train_sr.head(5)\n",
    "\n",
    "    # Cumulative Returns\n",
    "    eigen_train_fig = px.line(1. + eigen_train_rets.cumsum(),\n",
    "                              labels={\"value\" : \"Cumulative Return\"},\n",
    "                              title=f\"Top Eigen Portfolios Comparison vs EW Eigen Portfolio vs EW SP500\",\n",
    "                              width=1000,\n",
    "                              height=400)\n",
    "\n",
    "    eigen_train_sr.loc[[\"EW-Eigen\", \"EW-SP500\"]]\n",
    "\n",
    "\n",
    "    eigen_test_rets = get_eigen_rets(test_df=X_test_raw, \n",
    "                                     n_eigen_portfolios=14)\n",
    "\n",
    "    # Sharpe ratios\n",
    "    eigen_test_sr = get_eigen_stats(eigen_test_rets)\n",
    "    eigen_test_sr.head(5)\n",
    "\n",
    "    # Cumualtive returns\n",
    "    eigen_test_fig = px.line(1. + eigen_test_rets.cumsum(),\n",
    "                             labels={\"value\" : \"Cumulative Return\"},\n",
    "                             title=f\"Top Eigen Portfolios Comparison vs EW Eigen Portfolio vs EW SP500\",\n",
    "                             width=1000,\n",
    "                             height=400)\n",
    "\n",
    "    eigen_test_sr.loc[[\"EW-Eigen\", \"EW-SP500\"]]\n",
    "\n",
    "    return [get_eigen_rets(test_df=X_test_raw, n_eigen_portfolios=14)['EW-Eigen'], get_eigen_rets(test_df=X_test_raw, n_eigen_portfolios=14)['EW-SP500']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1846774",
   "metadata": {},
   "source": [
    "#### Explain Returns (Fama French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1930de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Data Frames\n",
    "def merge_df(ret_mtl, factors):\n",
    "    merge=pd.merge(ret_mtl,factors,on='Date')\n",
    "\n",
    "    # Factors from % to absolut\n",
    "    merge[['Mkt-RF','SMB','HML','RF']]=merge[['Mkt-RF','SMB','HML','RF']]/100\n",
    "\n",
    "    # Excess Returns\n",
    "    merge['EW-RF']=merge[list(merge.columns)[0]] - merge['RF']\n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c095c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "def regression_fama_french(merged_factor_df, portfolio_title):\n",
    "    y_1=merged_factor_df['EW-RF']\n",
    "    X_1=merged_factor_df[['Mkt-RF', 'SMB', 'HML']]\n",
    "\n",
    "    X_sn_1= sn.add_constant(X_1)\n",
    "    \n",
    "    # Regression statistics\n",
    "    model_1= sn.OLS(y_1,X_sn_1)\n",
    "    results_1=model_1.fit()\n",
    "    print(portfolio_title)\n",
    "    print(results_1.summary())\n",
    "    print('\\n')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc07d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly returns for Fama French\n",
    "def fama_french(portfolio):\n",
    "    \n",
    "    ew_eig_ret_mtl_list=[]\n",
    "    ew_SP500_ret_mtl_list=[]\n",
    "    factors_list=[]\n",
    "    ew_eig_ret_list=[]\n",
    "    for i in range(0, len(eigenportfolios)):\n",
    "        ew_eigen_ret=np.exp(eigenportfolios[i][0])\n",
    "        ew_SP500_ret=np.exp(eigenportfolios[i][1])\n",
    "\n",
    "        # For Quant Stats\n",
    "        ew_eig_ret_list.append(ew_eigen_ret)\n",
    "\n",
    "        ew_eigen_ret_mtl=ew_eigen_ret.resample('M').agg(lambda x: (x).prod()-1)\n",
    "        ew_SP500_ret_mtl=ew_SP500_ret.resample('M').agg(lambda x: (x).prod()-1)\n",
    "\n",
    "        #Fama French Factors\n",
    "        start=ew_eigen_ret_mtl.index[0]\n",
    "        end=ew_eigen_ret_mtl.index[ew_eigen_ret_mtl.size-1]\n",
    "        factors=reader.DataReader('F-F_Research_Data_Factors','famafrench',start,end)[0]\n",
    "\n",
    "        # Formating Month Dates\n",
    "        ew_eigen_ret_mtl.index=factors.index\n",
    "        ew_SP500_ret_mtl.index=factors.index\n",
    "\n",
    "        ew_eig_ret_mtl_list.append(ew_eigen_ret_mtl)\n",
    "        ew_SP500_ret_mtl_list.append(ew_SP500_ret_mtl)\n",
    "        factors_list.append(factors)\n",
    "    \n",
    "    # Regression statistics\n",
    "    for i in range(0,len(ew_eig_ret_mtl_list)):\n",
    "        regression_fama_french(merge_df(ew_eig_ret_mtl_list[i],factors_list[i]), f'EW-Eigen-Portfolio: {dates[i][0]} - {dates[i][1]}')\n",
    "        regression_fama_french(merge_df(ew_SP500_ret_mtl_list[i],factors_list[i]), f'EW- Index: {dates[i][0]} - {dates[i][1]}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6aac1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  499 of 499 completed\n",
      "\n",
      "3 Failed downloads:\n",
      "- JEC: No data found, symbol may be delisted\n",
      "- RTN: No data found, symbol may be delisted\n",
      "- SSE: None\n",
      "EW-Eigen-Portfolio: 2010-01-01 - 2021-06-01\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  EW-RF   R-squared:                       0.751\n",
      "Model:                            OLS   Adj. R-squared:                  0.715\n",
      "Method:                 Least Squares   F-statistic:                     21.06\n",
      "Date:                Wed, 24 Nov 2021   Prob (F-statistic):           1.55e-06\n",
      "Time:                        08:57:29   Log-Likelihood:                 59.591\n",
      "No. Observations:                  25   AIC:                            -111.2\n",
      "Df Residuals:                      21   BIC:                            -106.3\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0033      0.005      0.626      0.538      -0.008       0.014\n",
      "Mkt-RF         0.7428      0.094      7.940      0.000       0.548       0.937\n",
      "SMB           -0.4132      0.187     -2.214      0.038      -0.801      -0.025\n",
      "HML           -0.2051      0.113     -1.808      0.085      -0.441       0.031\n",
      "==============================================================================\n",
      "Omnibus:                        6.249   Durbin-Watson:                   2.337\n",
      "Prob(Omnibus):                  0.044   Jarque-Bera (JB):                1.817\n",
      "Skew:                          -0.014   Prob(JB):                        0.403\n",
      "Kurtosis:                       1.680   Cond. No.                         39.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "\n",
      "EW- Index: 2010-01-01 - 2021-06-01\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  EW-RF   R-squared:                       0.972\n",
      "Model:                            OLS   Adj. R-squared:                  0.968\n",
      "Method:                 Least Squares   F-statistic:                     246.6\n",
      "Date:                Wed, 24 Nov 2021   Prob (F-statistic):           1.59e-16\n",
      "Time:                        08:57:29   Log-Likelihood:                 78.234\n",
      "No. Observations:                  25   AIC:                            -148.5\n",
      "Df Residuals:                      21   BIC:                            -143.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0007      0.002      0.266      0.793      -0.005       0.006\n",
      "Mkt-RF         0.9739      0.044     21.946      0.000       0.882       1.066\n",
      "SMB           -0.0327      0.089     -0.370      0.715      -0.217       0.151\n",
      "HML            0.2932      0.054      5.447      0.000       0.181       0.405\n",
      "==============================================================================\n",
      "Omnibus:                        0.554   Durbin-Watson:                   2.051\n",
      "Prob(Omnibus):                  0.758   Jarque-Bera (JB):                0.093\n",
      "Skew:                           0.144   Prob(JB):                        0.955\n",
      "Kurtosis:                       3.083   Cond. No.                         39.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "\n",
      "[*********************100%***********************]  40 of 40 completed\n",
      "\n",
      "28 Failed downloads:\n",
      "- BAS: No data found, symbol may be delisted\n",
      "- CON: None\n",
      "- VNA: None\n",
      "- DHER: No data found, symbol may be delisted\n",
      "- DB1: No data found, symbol may be delisted\n",
      "- IFX: None\n",
      "- SHL: None\n",
      "- DBK: None\n",
      "- DWNI: No data found, symbol may be delisted\n",
      "- SRT3: No data found, symbol may be delisted\n",
      "- SIE: None\n",
      "- SY1: No data found, symbol may be delisted\n",
      "- HFG: None\n",
      "- BAYN: No data found, symbol may be delisted\n",
      "- 1COV: No data found, symbol may be delisted\n",
      "- PAH3: No data found, symbol may be delisted\n",
      "- VOW3: No data found, symbol may be delisted\n",
      "- DAI: None\n",
      "- FME: None\n",
      "- PUM: None\n",
      "- RWE: None\n",
      "- HEN3: No data found, symbol may be delisted\n",
      "- BMW: None\n",
      "- FRE: None\n",
      "- ZAL: None\n",
      "- MUV2: No data found, symbol may be delisted\n",
      "- EOAN: No data found, symbol may be delisted\n",
      "- QIA: None\n",
      "EW-Eigen-Portfolio: 2010-01-01 - 2021-06-01\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  EW-RF   R-squared:                       0.385\n",
      "Model:                            OLS   Adj. R-squared:                  0.309\n",
      "Method:                 Least Squares   F-statistic:                     5.016\n",
      "Date:                Wed, 24 Nov 2021   Prob (F-statistic):            0.00770\n",
      "Time:                        08:57:40   Log-Likelihood:                 24.320\n",
      "No. Observations:                  28   AIC:                            -40.64\n",
      "Df Residuals:                      24   BIC:                            -35.31\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0281      0.023      1.236      0.228      -0.019       0.075\n",
      "Mkt-RF         1.0497      0.418      2.514      0.019       0.188       1.911\n",
      "SMB           -1.3560      0.798     -1.700      0.102      -3.003       0.291\n",
      "HML            1.0743      0.499      2.155      0.041       0.045       2.103\n",
      "==============================================================================\n",
      "Omnibus:                       10.066   Durbin-Watson:                   2.469\n",
      "Prob(Omnibus):                  0.007   Jarque-Bera (JB):                9.053\n",
      "Skew:                           1.010   Prob(JB):                       0.0108\n",
      "Kurtosis:                       4.918   Cond. No.                         39.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "\n",
      "EW- Index: 2010-01-01 - 2021-06-01\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  EW-RF   R-squared:                       0.788\n",
      "Model:                            OLS   Adj. R-squared:                  0.762\n",
      "Method:                 Least Squares   F-statistic:                     29.75\n",
      "Date:                Wed, 24 Nov 2021   Prob (F-statistic):           2.96e-08\n",
      "Time:                        08:57:40   Log-Likelihood:                 43.034\n",
      "No. Observations:                  28   AIC:                            -78.07\n",
      "Df Residuals:                      24   BIC:                            -72.74\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0293      0.012     -2.520      0.019      -0.053      -0.005\n",
      "Mkt-RF         1.5606      0.214      7.292      0.000       1.119       2.002\n",
      "SMB            0.6993      0.409      1.710      0.100      -0.145       1.543\n",
      "HML            0.2388      0.256      0.934      0.359      -0.289       0.766\n",
      "==============================================================================\n",
      "Omnibus:                        0.099   Durbin-Watson:                   1.898\n",
      "Prob(Omnibus):                  0.952   Jarque-Bera (JB):                0.036\n",
      "Skew:                          -0.035   Prob(JB):                        0.982\n",
      "Kurtosis:                       2.838   Cond. No.                         39.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chosing Dates\n",
    "#dates=[[\"1991-06-01\", \"2001-06-01\"],[\"2001-06-01\", \"2011-06-01\"],[\"2011-06-01\", \"2021-06-01\"]]\n",
    "dates=[[\"2010-01-01\", \"2021-06-01\"]]\n",
    "tickers=['S&P 500', 'DAX']\n",
    "\n",
    "# Generating Eigenportfolios and performing Fama French\n",
    "for j in tickers:\n",
    "    eigenportfolios=[]\n",
    "    for i in dates:\n",
    "        eigenportfolios.append(eigenportfolio(i[0],i[1],j))\n",
    "\n",
    "    # Performing Fama French Analysis\n",
    "    fama_french(eigenportfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e4ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Several companys from today dont exist 30 years ago and vice versa,therefore Fama French gets less reliable\n",
    "\n",
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1bd5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quant Stats\n",
    "#for i in range(0,len(ew_eig_ret_list)):\n",
    "    #qs.reports.basic(ew_eig_ret_list[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
